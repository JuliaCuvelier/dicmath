{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aeaf399",
   "metadata": {},
   "source": [
    "# Speech-to-text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0084dc87",
   "metadata": {},
   "source": [
    "Define `AZURE_SPEECH_KEY`, `AZURE_SPEECH_REGION`, `LANGUAGE`, `SHORT_LANGUAGE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330ff309",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('../instance/config.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f515067",
   "metadata": {},
   "source": [
    "## Azure Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1dfaf6",
   "metadata": {},
   "source": [
    "[Speech-to-text quickstart](https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/get-started-speech-to-text?pivots=programming-language-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e6ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8984e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da1b57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text_azure():\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)\n",
    "    speech_config.speech_recognition_language = LANGUAGE\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    print('Speak into your microphone.')\n",
    "    speech_recognition_result = speech_recognizer.recognize_once_async().get()\n",
    "\n",
    "    if speech_recognition_result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        return speech_recognition_result.text\n",
    "    elif speech_recognition_result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print('No speech could be recognized: {}'.format(speech_recognition_result.no_match_details))\n",
    "    elif speech_recognition_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_recognition_result.cancellation_details\n",
    "        print('Speech Recognition canceled: {}'.format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print('Error details: {}'.format(cancellation_details.error_details))\n",
    "            print('Did you set the speech resource key and region values?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40cc57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak into your microphone.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4+6-2 égale 8.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = speech_to_text_azure()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c808bb9e",
   "metadata": {},
   "source": [
    "## Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b11c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install SpeechRecognition\n",
    "# !pip install PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b315910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5b69be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_from_microphone():\n",
    "    r = sr.Recognizer()\n",
    "    \n",
    "    with sr.Microphone() as source:\n",
    "        print('Speak into your microphone.')\n",
    "        audio = r.listen(source)\n",
    "        return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1c576e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text_google():\n",
    "    audio = audio_from_microphone()\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "    return r.recognize_google(audio, language=LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ceaf83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak into your microphone.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4 + 6 - 2 = 8'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = speech_to_text_google()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c040721",
   "metadata": {},
   "source": [
    "## Whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bc7fee",
   "metadata": {},
   "source": [
    "[Setup](https://github.com/openai/whisper#setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7795be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/openai/whisper.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c39a5e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc474034",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model('large') # tiny, base, small, medium, large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "340b4754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text_whisper(model, translate=False):\n",
    "    audio = audio_from_microphone()\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix='.wav') as f:\n",
    "        f.write(audio.get_wav_data())\n",
    "        f.flush()\n",
    "        result = model.transcribe(f.name, \n",
    "                                  language=SHORT_LANGUAGE, \n",
    "                                  task='Translate' if translate else None, \n",
    "                                  fp16=False)\n",
    "\n",
    "    return result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8dba7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak into your microphone.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 4 plus 6 moins 2 égale 8.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = speech_to_text_whisper(model)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58909307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak into your microphone.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 4 plus 6 minus 2 equals 8.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_text = speech_to_text_whisper(model, translate=True)\n",
    "translated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
